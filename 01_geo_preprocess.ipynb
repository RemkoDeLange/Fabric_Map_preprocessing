{"cells":[{"cell_type":"code","source":["%%configure -f\n","{\n","    \"jars\": [\n","        \"<ADD ADFS PATH>/geotools-wrapper-1.8.0-33.1.jar\",\n","        \"<ADD ADFS PATH>/sedona-spark-shaded-3.5_2.12-1.8.0.jar\" \n","        ]\n","}"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:29:04.1602098Z","session_start_time":"2026-02-03T09:29:04.379834Z","execution_start_time":"2026-02-03T09:32:21.736648Z","execution_finish_time":"2026-02-03T09:32:21.8286106Z","parent_msg_id":"ca36047d-5b40-4e8d-8058-d428c9986c07"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, -1, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false}},"id":"f72618f3-8e86-42fd-94cf-3f0dcd60fdf5"},{"cell_type":"code","source":["# Test cell, to check for correct installation Sedona\n","\n","from sedona.spark import *\n","\n","sedona = SedonaContext.create(spark)\n","\n","sedona.sql(\"SELECT ST_GeomFromEWKT('SRID=4269;POINT(40.7128 -74.0060)')\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:32:33.6527607Z","session_start_time":null,"execution_start_time":"2026-02-03T09:32:59.3455744Z","execution_finish_time":"2026-02-03T09:33:06.6799923Z","parent_msg_id":"702da57f-a2cc-4d1b-a2c4-6643a8e883b6"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------+\n|st_geomfromewkt(SRID=4269;POINT(40.7128 -74.0060))|\n+--------------------------------------------------+\n|                              POINT (40.7128 -7...|\n+--------------------------------------------------+\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d41370cf-26c5-42f6-ab12-2aedee74f72f"},{"cell_type":"code","source":["# check the directories within default lakehouse\n","\n","import os\n","\n","root = \"/lakehouse/default/Files\"\n","items = os.listdir(root)\n","\n","for name in items:\n","    full = os.path.join(root, name)\n","    print(f\"{'DIR ' if os.path.isdir(full) else 'FILE'}  {full}\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:35:21.7514688Z","session_start_time":null,"execution_start_time":"2026-02-03T09:35:21.7526001Z","execution_finish_time":"2026-02-03T09:35:23.2648468Z","parent_msg_id":"5c76baff-2cc6-4bac-9c3c-578d16dfec9c"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DIR   /lakehouse/default/Files/Apache_Sedona_jars\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77f306fe-3ac6-4738-930c-b0143891842c"},{"cell_type":"code","source":["# Download BAG data (building footprints Netherlands)\n","\n","# Import required modules\n","import os\n","import requests\n","from datetime import datetime\n","\n","# Create folder name with current month and year as postfix\n","current_time = datetime.now()\n","folder_name = f\"BAG_download_{current_time.strftime('%Y%m')}\"\n","lh_folder = f\"/lakehouse/default/Files/{folder_name}\"\n","\n","# Ensure the target folder exists\n","os.makedirs(lh_folder, exist_ok=True)\n","\n","# File download GeoPackage\n","# For further information see https://service.pdok.nl/lv/bag/atom/bag.xml\n","gpkg_url = \"https://service.pdok.nl/lv/bag/atom/downloads/bag-light.gpkg\"\n","gpkg_path = os.path.join(lh_folder, \"bag-light.gpkg\")\n","\n","# Download the GeoPackage file from the given URL\n","response = requests.get(gpkg_url, stream=True)\n","with open(gpkg_path, \"wb\") as f:\n","    for chunk in response.iter_content(chunk_size=1024):\n","        if chunk:\n","            f.write(chunk)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:35:29.1617302Z","session_start_time":null,"execution_start_time":"2026-02-03T09:35:29.1629471Z","execution_finish_time":"2026-02-03T09:39:32.7451458Z","parent_msg_id":"deabd1bb-2196-449e-b5c2-e9cbf40a4ca6"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false}},"id":"bf448c2a-b144-41e9-9148-2e66f64a9b29"},{"cell_type":"code","source":["# Download BRT data (bestuurlijke gebieden / administrative areas Netherlands)\n","\n","# Import required modules\n","import os\n","import requests\n","from datetime import datetime\n","\n","# Create folder name with current month and year as postfix\n","current_time = datetime.now()\n","folder_name = f\"BRK_download_{current_time.strftime('%Y')}\"\n","lh_folder = f\"/lakehouse/default/Files/{folder_name}\"\n","\n","# Ensure the target folder exists\n","os.makedirs(lh_folder, exist_ok=True)\n","\n","# File download GeoPackage\n","# For further information see https://nationaalgeoregister.nl/geonetwork/srv/dut/catalog.search#/metadata/208bc283-7c66-4ce7-8ad3-1cf3e8933fb5\n","gpkg_url = \"https://service.pdok.nl/kadaster/brk-bestuurlijke-gebieden/atom/downloads/BestuurlijkeGebieden_2026.gpkg\"\n","gpkg_path = os.path.join(lh_folder, \"BestuurlijkeGebieden_2026.gpkg\")\n","\n","# Download the GeoPackage file from the given URL\n","response = requests.get(gpkg_url, stream=True)\n","with open(gpkg_path, \"wb\") as f:\n","    for chunk in response.iter_content(chunk_size=1024):\n","        if chunk:\n","            f.write(chunk)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:44:21.9796063Z","session_start_time":null,"execution_start_time":"2026-02-03T09:44:21.9808069Z","execution_finish_time":"2026-02-03T09:44:25.1331706Z","parent_msg_id":"c8948d42-2cb1-4656-987c-ff845bd2f852"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"32b277d1-022c-4a91-ad3f-ebc037433812"},{"cell_type":"code","source":["\n","# ===========================\n","# BAG + Provinces GeoPackage → GeoJSON (WGS84 / EPSG:4326), split to < 1 GB per file (with 4 KB buffer)\n","# Sedona 1.8 native GeoPackage reader; auto-discover SQLite table names & per-layer CRS\n","# Parallel province processing: ONE broadcast spatial join for PAND and ONE for VBO\n","# Bundle PAND and VERBLIJFSOBJECT per Province (attribute 'naam'); export provinces layer as BRK_provincies\n","# Unique temp directories per chunk; versioned output folder (_v01)\n","# ===========================\n","\n","from sedona.spark import *\n","sedona = SedonaContext.create(spark)\n","\n","from pyspark.sql import functions as F, Window, types as T\n","from pyspark import StorageLevel\n","from notebookutils import mssparkutils\n","from datetime import datetime\n","from uuid import uuid4\n","import os, re, sqlite3, shutil, time\n","\n","# --- Default CRS (used if GPKG doesn't provide SRS metadata) ---\n","DEFAULT_SOURCE_CRS = \"EPSG:28992\"   # RD New (typical for BAG & PDOK datasets)\n","TARGET_CRS = \"EPSG:4326\"            # WGS84\n","\n","# Friendly layer selectors for BAG (we will resolve real table names from gpkg_contents)\n","BAG_FRIENDLY_LAYERS = {\n","    \"pand\":            [\"pand\"],\n","    \"verblijfsobject\": [\"verblijfsobject\", \"vbo\"],\n","    \"standplaats\":     [\"standplaats\"],\n","    \"ligplaats\":       [\"ligplaats\"],\n","}\n","\n","# Provinces layer selector (resolve actual table; typical name: 'provinciegebied')\n","PROV_FRIENDLY_LAYERS = {\n","    \"provincie\": [\"provincie\", \"provinciegebied\"]\n","}\n","PROV_NAME_COL = \"naam\"  # Provinces attribute for the province name\n","\n","# Sedona / join tuning (adjust to your cluster)\n","spark.conf.set(\"sedona.join.gridtype\", \"kdbtree\")\n","spark.conf.set(\"sedona.join.index\", \"true\")\n","spark.conf.set(\"sedona.join.buildOnSpatialPartitionedRDD\", \"true\")  # accelerate indexed joins\n","spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")               # for wide shuffles\n","\n","# Parallelism target: ~4x core count is a reasonable start\n","TARGET_PARTITIONS = 32\n","\n","# --- Input dirs (BAG per month; Provinces per year) and versioned output ---\n","current_time    = datetime.now()\n","version_postfix = \"v01\"  # bump to v02/v03 for isolated runs\n","bag_folder_name_in   = f\"BAG_download_{current_time.strftime('%Y%m')}\"\n","prov_folder_name_in  = f\"BRK_download_{current_time.strftime('%Y')}\"   # from your download cell\n","out_folder_name      = f\"BAG_geojson_province_WGS84_4326_{current_time.strftime('%Y%m')}_{version_postfix}\"\n","\n","# Lakehouse mounted paths (use file: URIs for Spark/Sedona)\n","BAG_IN_DIR   = f\"file:/lakehouse/default/Files/{bag_folder_name_in}\"\n","PROV_IN_DIR  = f\"file:/lakehouse/default/Files/{prov_folder_name_in}\"\n","OUTPUT_DIR   = f\"file:/lakehouse/default/Files/{out_folder_name}\"\n","mssparkutils.fs.mkdirs(OUTPUT_DIR)\n","\n","# ---- helpers ----\n","def sanitize_filename(s: str) -> str:\n","    s = (s or \"\").strip()\n","    s = re.sub(r\"[^\\w\\-]+\", \"_\", s)\n","    s = s.strip(\"_\")\n","    return s or \"unknown\"\n","\n","def rm_any(path_uri: str, recursive: bool = True):\n","    \"\"\"Remove paths via mssparkutils, Hadoop FS, and local OS for robustness.\"\"\"\n","    # 1) mssparkutils\n","    try:\n","        if mssparkutils.fs.exists(path_uri):\n","            mssparkutils.fs.rm(path_uri, recursive)\n","    except Exception:\n","        pass\n","    # 2) Hadoop FS\n","    try:\n","        jpath = spark._jvm.org.apache.hadoop.fs.Path(path_uri)\n","        fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n","        fs.delete(jpath, recursive)\n","    except Exception:\n","        pass\n","    # 3) Local OS\n","    try:\n","        local_path = path_uri.replace(\"file:\", \"\")\n","        if os.path.isdir(local_path):\n","            shutil.rmtree(local_path, ignore_errors=True)\n","        elif os.path.isfile(local_path):\n","            os.remove(local_path)\n","    except Exception:\n","        pass\n","\n","def detect_geometry_column(df):\n","    for cand in [\"geometry\", \"geom\", \"the_geom\", \"wkb\", \"wkt\"]:\n","        if cand in df.columns:\n","            return cand\n","    raise RuntimeError(f\"No geometry-like column found. Columns: {df.columns}\")\n","\n","def to_wgs84(df, geom_col, src_crs: str):\n","    \"\"\"Transform geometries to WGS84 from per-layer source CRS.\"\"\"\n","    source = src_crs or DEFAULT_SOURCE_CRS\n","    return df.selectExpr(\"*\", f\"ST_Transform({geom_col}, '{source}', '{TARGET_CRS}') AS geometry_wgs84\")\n","\n","def to_feature_df(gdf_wgs84, include_geom_col=\"geometry_wgs84\", drop_cols=None):\n","    if drop_cols is None: drop_cols = []\n","    prop_cols = [c for c in gdf_wgs84.columns if c not in {include_geom_col} | set(drop_cols)]\n","    return (\n","        gdf_wgs84\n","        .withColumn(\"geom_json\", F.expr(f\"ST_AsGeoJSON({include_geom_col})\"))\n","        .withColumn(\"props_json\", F.to_json(F.struct(*[F.col(c) for c in prop_cols])))\n","        .select(\n","            F.concat(\n","                F.lit('{\"type\":\"Feature\",\"geometry\":'),\n","                F.col(\"geom_json\"),\n","                F.lit(',\"properties\":'),\n","                F.col(\"props_json\"),\n","                F.lit(\"}\")\n","            ).alias(\"feature_json\")\n","        )\n","    )\n","\n","def write_featurecollection_chunks(df_features, final_base_name):\n","    \"\"\"Write FeatureCollection GeoJSON under OUTPUT_DIR, split to ≤ 1 GB with 4 KB buffer.\"\"\"\n","    MAX_BYTES = 1 * 1024 * 1024 * 1024 - 4096\n","\n","    sized = (\n","        df_features\n","        .withColumn(\"feature_bytes\", F.length(\"feature_json\").cast(\"long\") + F.lit(2))  # +2 for comma/newline\n","        .withColumn(\"row_id\", F.monotonically_increasing_id())\n","    )\n","    w = Window.orderBy(\"row_id\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n","    sized = sized.withColumn(\"cum_bytes\", F.sum(\"feature_bytes\").over(w))\n","    chunked = sized.withColumn(\"chunk_id\", F.floor((F.col(\"cum_bytes\") - F.lit(1)) / F.lit(MAX_BYTES))).cache()\n","\n","    chunk_ids = [r.chunk_id for r in chunked.select(\"chunk_id\").distinct().collect()]\n","    print(f\"Writing {final_base_name}: {len(chunk_ids)} chunk(s)\")\n","\n","    for idx, cid in enumerate(sorted(chunk_ids), start=1):\n","        out_file = (\n","            f\"{OUTPUT_DIR}/{final_base_name}.geojson\" if len(chunk_ids) == 1\n","            else f\"{OUTPUT_DIR}/{final_base_name}_{idx:02d}.geojson\"\n","        )\n","        # Unique temp dir to avoid any rerun collisions\n","        tmp_out_dir = f\"{OUTPUT_DIR}/__tmp_{final_base_name}_{idx:02d}_{uuid4().hex}\"\n","\n","        # Build FeatureCollection stream (header, features, footer)\n","        rdd = (\n","            chunked.filter(F.col(\"chunk_id\") == cid)\n","            .select(\"feature_json\")\n","            .rdd\n","            .map(lambda r: r[0])\n","        )\n","\n","        def add_header_footer(_, it):\n","            yield '{\"type\":\"FeatureCollection\",\"features\":['\n","            first = True\n","            for f in it:\n","                if first: yield f; first = False\n","                else:     yield \",\" + f\n","            yield ']}'\n","\n","        rdd_fc = rdd.coalesce(1).mapPartitionsWithIndex(add_header_footer)\n","\n","        df_text = spark.createDataFrame(rdd_fc.map(lambda s: (s,)), [\"value\"])\n","        df_text.coalesce(1).write.text(tmp_out_dir)  # temp path is unique; no overwrite required\n","\n","        # Move single part to final file name\n","        parts = mssparkutils.fs.ls(tmp_out_dir)\n","        part_files = [p.path for p in parts if p.path.endswith(\"/part-00000\")]\n","        if not part_files:\n","            part_files = [p.path for p in parts if \"/part-\" in p.path]\n","        if not part_files:\n","            rm_any(tmp_out_dir, recursive=True)\n","            raise RuntimeError(f\"No output part file produced for {final_base_name}, chunk {idx}\")\n","\n","        # Overwrite final if exists\n","        rm_any(out_file, recursive=True)\n","        mssparkutils.fs.mv(part_files[0], out_file, True, True)\n","        rm_any(tmp_out_dir, recursive=True)\n","\n","        meta = [f for f in mssparkutils.fs.ls(OUTPUT_DIR) if f.path == out_file]\n","        if meta:\n","            print(f\"  -> {out_file}  size={meta[0].size} bytes\")\n","\n","# ---- GeoPackage utilities (discover tables and per-layer CRS) ----\n","def list_feature_tables(local_gpkg_path: str):\n","    conn = sqlite3.connect(local_gpkg_path)\n","    cur = conn.cursor()\n","    cur.execute(\"SELECT table_name FROM gpkg_contents WHERE data_type='features'\")\n","    rows = [r[0] for r in cur.fetchall()]\n","    conn.close()\n","    return rows\n","\n","def pick_table(tables, candidates):\n","    \"\"\"Return first table whose name contains any candidate substring (case-insensitive).\"\"\"\n","    low = [t.lower() for t in tables]\n","    for cand in candidates:\n","        c = cand.lower()\n","        for i, t in enumerate(low):\n","            if c in t:\n","                return tables[i]\n","    return None\n","\n","def get_layer_epsg(local_gpkg_path: str, table_name: str) -> str:\n","    \"\"\"\n","    Return 'EPSG:<code>' for the layer if available from gpkg_geometry_columns + gpkg_spatial_ref_sys.\n","    Fallback to DEFAULT_SOURCE_CRS if not resolvable.\n","    \"\"\"\n","    try:\n","        conn = sqlite3.connect(local_gpkg_path)\n","        cur = conn.cursor()\n","        cur.execute(\"\"\"\n","            SELECT srs.organization, srs.organization_coordsys_id\n","            FROM gpkg_geometry_columns gc\n","            JOIN gpkg_spatial_ref_sys srs\n","              ON gc.srs_id = srs.srs_id\n","            WHERE gc.table_name = ?\n","        \"\"\", (table_name,))\n","        row = cur.fetchone()\n","        conn.close()\n","        if row and row[0] and row[1]:\n","            org, org_id = row[0], row[1]\n","            if str(org).upper() == \"EPSG\":\n","                return f\"EPSG:{org_id}\"\n","    except Exception:\n","        pass\n","    return DEFAULT_SOURCE_CRS\n","\n","def read_layer_geopackage(gpkg_uri_file: str, table_name: str):\n","    \"\"\"Sedona GeoPackage reader (point to specific .gpkg file via file: URI).\"\"\"\n","    return (\n","        sedona.read\n","        .format(\"geopackage\")\n","        .option(\"tableName\", table_name)\n","        .load(gpkg_uri_file)\n","    )\n","\n","# ---------------------------\n","# Locate the two GeoPackages\n","# ---------------------------\n","\n","# BAG\n","bag_entries = mssparkutils.fs.ls(BAG_IN_DIR)\n","bag_gpkg_files = [e.name for e in bag_entries if e.isFile and e.name.lower().endswith(\".gpkg\")]\n","if not bag_gpkg_files:\n","    raise FileNotFoundError(f\"No BAG .gpkg found in {BAG_IN_DIR}\")\n","if len(bag_gpkg_files) > 1:\n","    print(f\"[Info] Multiple BAG .gpkg found; using first: {bag_gpkg_files[0]}\")\n","BAG_GPKG_URI  = f\"{BAG_IN_DIR}/{bag_gpkg_files[0]}\"\n","BAG_GPKG_LOCAL = BAG_GPKG_URI.replace(\"file:\", \"\")\n","print(f\"Using BAG GeoPackage: {BAG_GPKG_URI}\")\n","\n","# Provinces (BestuurlijkeGebieden)\n","prov_entries = mssparkutils.fs.ls(PROV_IN_DIR)\n","prov_gpkg_files = [e.name for e in prov_entries if e.isFile and e.name.lower().endswith(\".gpkg\")]\n","if not prov_gpkg_files:\n","    raise FileNotFoundError(f\"No provinces .gpkg found in {PROV_IN_DIR}\")\n","if len(prov_gpkg_files) > 1:\n","    print(f\"[Info] Multiple province .gpkg found; using first: {prov_gpkg_files[0]}\")\n","PROV_GPKG_URI  = f\"{PROV_IN_DIR}/{prov_gpkg_files[0]}\"\n","PROV_GPKG_LOCAL = PROV_GPKG_URI.replace(\"file:\", \"\")\n","print(f\"Using Provinces GeoPackage: {PROV_GPKG_URI}\")\n","\n","# ---------------------------\n","# Resolve actual table names\n","# ---------------------------\n","\n","bag_tables  = list_feature_tables(BAG_GPKG_LOCAL)\n","prov_tables = list_feature_tables(PROV_GPKG_LOCAL)\n","print(\"BAG feature tables:\", bag_tables)\n","print(\"Province feature tables:\", prov_tables)\n","\n","tbl_pand          = pick_table(bag_tables,  BAG_FRIENDLY_LAYERS[\"pand\"])\n","tbl_vbo           = pick_table(bag_tables,  BAG_FRIENDLY_LAYERS[\"verblijfsobject\"])\n","tbl_standplaats   = pick_table(bag_tables,  BAG_FRIENDLY_LAYERS[\"standplaats\"])\n","tbl_ligplaats     = pick_table(bag_tables,  BAG_FRIENDLY_LAYERS[\"ligplaats\"])\n","tbl_prov          = pick_table(prov_tables, PROV_FRIENDLY_LAYERS[\"provincie\"])\n","\n","missing = []\n","if not tbl_pand:        missing.append(\"pand\")\n","if not tbl_vbo:         missing.append(\"verblijfsobject\")\n","if not tbl_prov:        missing.append(\"provinciegebied\")\n","# standplaats/ligplaats are optional\n","\n","if missing:\n","    raise RuntimeError(f\"Could not find expected tables: {missing}\\n\"\n","                       f\"BAG tables: {bag_tables}\\nProvince tables: {prov_tables}\")\n","\n","print(\"Resolved table names:\",\n","      {\"pand\": tbl_pand, \"verblijfsobject\": tbl_vbo,\n","       \"standplaats\": tbl_standplaats, \"ligplaats\": tbl_ligplaats,\n","       \"provincie\": tbl_prov})\n","\n","# ---------------------------\n","# Load layers and transform to WGS84 using per-layer CRS\n","# ---------------------------\n","\n","# Determine per-layer EPSG (if available), fallback to RD New\n","epsg_pand = get_layer_epsg(BAG_GPKG_LOCAL,  tbl_pand)\n","epsg_vbo  = get_layer_epsg(BAG_GPKG_LOCAL,  tbl_vbo)\n","epsg_prov = get_layer_epsg(PROV_GPKG_LOCAL, tbl_prov)\n","\n","gdf_pand_src = read_layer_geopackage(BAG_GPKG_URI,  tbl_pand)\n","gdf_vbo_src  = read_layer_geopackage(BAG_GPKG_URI,  tbl_vbo)\n","gdf_prov_src = read_layer_geopackage(PROV_GPKG_URI, tbl_prov)\n","\n","geom_pand = detect_geometry_column(gdf_pand_src)\n","geom_vbo  = detect_geometry_column(gdf_vbo_src)\n","geom_prov = detect_geometry_column(gdf_prov_src)\n","\n","# Repartition early to unlock parallelism\n","gdf_pand_wgs = to_wgs84(gdf_pand_src, geom_pand, epsg_pand).repartition(TARGET_PARTITIONS).persist(StorageLevel.MEMORY_AND_DISK)\n","gdf_vbo_wgs  = to_wgs84(gdf_vbo_src,  geom_vbo,  epsg_vbo ).repartition(TARGET_PARTITIONS).persist(StorageLevel.MEMORY_AND_DISK)\n","gdf_prov_wgs = to_wgs84(gdf_prov_src, geom_prov, epsg_prov).repartition(4).cache()\n","\n","# Materialize\n","_ = gdf_pand_wgs.count(); _ = gdf_vbo_wgs.count(); _ = gdf_prov_wgs.count()\n","\n","# ---------------------------\n","# Whole-layer exports (provinces + optional standplaats/ligplaats)\n","# ---------------------------\n","\n","print(\"\\nExporting provinces and optional whole layers with size-aware chunking...\")\n","\n","# Provinces (rename to BRK_provincies as requested)\n","write_featurecollection_chunks(\n","    to_feature_df(gdf_prov_wgs, include_geom_col=\"geometry_wgs84\"),\n","    final_base_name=\"BRK_provincies\"\n",")\n","\n","# Optional whole-layer exports if present\n","if tbl_standplaats:\n","    epsg_stand = get_layer_epsg(BAG_GPKG_LOCAL, tbl_standplaats)\n","    gdf_stand_src = read_layer_geopackage(BAG_GPKG_URI, tbl_standplaats)\n","    geom_stand = detect_geometry_column(gdf_stand_src)\n","    gdf_stand_wgs = to_wgs84(gdf_stand_src, geom_stand, epsg_stand).repartition(8).cache()\n","    write_featurecollection_chunks(\n","        to_feature_df(gdf_stand_wgs, include_geom_col=\"geometry_wgs84\"),\n","        final_base_name=\"BAG_standplaats\"\n","    )\n","\n","if tbl_ligplaats:\n","    epsg_lig = get_layer_epsg(BAG_GPKG_LOCAL, tbl_ligplaats)\n","    gdf_lig_src = read_layer_geopackage(BAG_GPKG_URI, tbl_ligplaats)\n","    geom_lig = detect_geometry_column(gdf_lig_src)\n","    gdf_lig_wgs = to_wgs84(gdf_lig_src, geom_lig, epsg_lig).repartition(8).cache()\n","    write_featurecollection_chunks(\n","        to_feature_df(gdf_lig_wgs, include_geom_col=\"geometry_wgs84\"),\n","        final_base_name=\"BAG_ligplaats\"\n","    )\n","\n","# ---------------------------\n","# Parallel per-Province processing (ONE spatial join per layer)\n","# ---------------------------\n","\n","print(\"\\nExporting per Province (PAND and VERBLIJFSOBJECT) with parallel join …\")\n","\n","# Build one unioned geometry per province (12 rows)\n","t0 = time.time()\n","prov_unioned = (\n","    gdf_prov_wgs\n","    .groupBy(PROV_NAME_COL)\n","    .agg(F.expr(\"ST_Union_Aggr(geometry_wgs84) AS province_geom\"))\n","    .repartition(12)\n","    .cache()\n",")\n","_ = prov_unioned.count()\n","print(f\"Built province unions in {time.time() - t0:.1f}s\")\n","\n","# ONE distributed join for PAND\n","t1 = time.time()\n","pand_with_province = (\n","    gdf_pand_wgs.alias(\"p\")\n","    .join(\n","        F.broadcast(prov_unioned).alias(\"r\"),\n","        F.expr(\"ST_Intersects(p.geometry_wgs84, r.province_geom)\")\n","    )\n","    .select(\n","        F.col(f\"r.{PROV_NAME_COL}\").alias(PROV_NAME_COL),\n","        *[F.col(f\"p.{c}\").alias(c) for c in gdf_pand_wgs.columns]\n","    )\n","    .repartition(TARGET_PARTITIONS, F.col(PROV_NAME_COL))     # cluster by province for fast filtering\n","    .persist(StorageLevel.MEMORY_AND_DISK)\n",")\n","pand_count = pand_with_province.count()\n","print(f\"PAND join produced {pand_count} rows in {time.time() - t1:.1f}s\")\n","\n","# ONE distributed join for VBO\n","t2 = time.time()\n","vbo_with_province = (\n","    gdf_vbo_wgs.alias(\"v\")\n","    .join(\n","        F.broadcast(prov_unioned).alias(\"r\"),\n","        F.expr(\"ST_Intersects(v.geometry_wgs84, r.province_geom)\")\n","    )\n","    .select(\n","        F.col(f\"r.{PROV_NAME_COL}\").alias(PROV_NAME_COL),\n","        *[F.col(f\"v.{c}\").alias(c) for c in gdf_vbo_wgs.columns]\n","    )\n","    .repartition(TARGET_PARTITIONS, F.col(PROV_NAME_COL))\n","    .persist(StorageLevel.MEMORY_AND_DISK)\n",")\n","vbo_count = vbo_with_province.count()\n","print(f\"VBO join produced {vbo_count} rows in {time.time() - t2:.1f}s\")\n","\n","# Province list (distinct once)\n","prov_names = [r[PROV_NAME_COL] for r in prov_unioned.select(PROV_NAME_COL).collect()]\n","print(f\"Writing per-province GeoJSON for {len(prov_names)} provinces …\")\n","\n","for prov_name in prov_names:\n","    safe_prov = sanitize_filename(prov_name)\n","    print(f\"  -> Writing province: {prov_name}\")\n","\n","    # Filter (cheap – data already partitioned by province)\n","    df_pand_prov = pand_with_province.filter(F.col(PROV_NAME_COL) == prov_name)\n","    write_featurecollection_chunks(\n","        to_feature_df(df_pand_prov, include_geom_col=\"geometry_wgs84\"),\n","        final_base_name=f\"BAG_{safe_prov}\"\n","    )\n","\n","    df_vbo_prov = vbo_with_province.filter(F.col(PROV_NAME_COL) == prov_name)\n","    write_featurecollection_chunks(\n","        to_feature_df(df_vbo_prov, include_geom_col=\"geometry_wgs84\"),\n","        final_base_name=f\"BAG_verblijfsobject_{safe_prov}\"\n","    )\n","\n","print(\"\\nAll files processed.\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"83c40b2b-b419-4d14-baf9-37efeb6f1d82","normalized_state":"finished","queued_time":"2026-02-03T09:45:10.3063942Z","session_start_time":null,"execution_start_time":"2026-02-03T09:45:10.3080481Z","execution_finish_time":"2026-02-03T10:23:08.8849278Z","parent_msg_id":"85ef05c8-3f6d-4806-a919-550897931017"},"text/plain":"StatementMeta(, 83c40b2b-b419-4d14-baf9-37efeb6f1d82, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using BAG GeoPackage: file:/lakehouse/default/Files/BAG_download_202602/bag-light.gpkg\nUsing Provinces GeoPackage: file:/lakehouse/default/Files/BRK_download_2026/BestuurlijkeGebieden_2026.gpkg\nBAG feature tables: ['pand', 'verblijfsobject', 'ligplaats', 'standplaats', 'woonplaats']\nProvince feature tables: ['gemeentegebied', 'landgebied', 'provinciegebied']\nResolved table names: {'pand': 'pand', 'verblijfsobject': 'verblijfsobject', 'standplaats': 'standplaats', 'ligplaats': 'ligplaats', 'provincie': 'provinciegebied'}\n\nExporting provinces and optional whole layers with size-aware chunking...\nWriting BRK_provincies: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BRK_provincies.geojson  size=8518916 bytes\nWriting BAG_standplaats: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_standplaats.geojson  size=50213400 bytes\nWriting BAG_ligplaats: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_ligplaats.geojson  size=14097170 bytes\n\nExporting per Province (PAND and VERBLIJFSOBJECT) with parallel join …\nBuilt province unions in 3.8s\nPAND join produced 11318284 rows in 195.6s\nVBO join produced 9889995 rows in 183.4s\nWriting per-province GeoJSON for 12 provinces …\n  -> Writing province: Gelderland\nWriting BAG_Gelderland: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Gelderland_01.geojson  size=1073737304 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Gelderland_02.geojson  size=301395653 bytes\nWriting BAG_verblijfsobject_Gelderland: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Gelderland.geojson  size=899658653 bytes\n  -> Writing province: Flevoland\nWriting BAG_Flevoland: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Flevoland.geojson  size=255560732 bytes\nWriting BAG_verblijfsobject_Flevoland: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Flevoland.geojson  size=176622021 bytes\n  -> Writing province: Fryslân\nWriting BAG_Fryslân: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Fryslân.geojson  size=484487328 bytes\nWriting BAG_verblijfsobject_Fryslân: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Fryslân.geojson  size=301056544 bytes\n  -> Writing province: Noord-Holland\nWriting BAG_Noord-Holland: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Noord-Holland_01.geojson  size=1073737557 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Noord-Holland_02.geojson  size=298388167 bytes\nWriting BAG_verblijfsobject_Noord-Holland: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Noord-Holland_01.geojson  size=1073757348 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Noord-Holland_02.geojson  size=302774023 bytes\n  -> Writing province: Groningen\nWriting BAG_Groningen: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Groningen.geojson  size=383953130 bytes\nWriting BAG_verblijfsobject_Groningen: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Groningen.geojson  size=272409383 bytes\n  -> Writing province: Utrecht\nWriting BAG_Utrecht: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Utrecht.geojson  size=726877811 bytes\nWriting BAG_verblijfsobject_Utrecht: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Utrecht.geojson  size=579084317 bytes\n  -> Writing province: Drenthe\nWriting BAG_Drenthe: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Drenthe.geojson  size=366255201 bytes\nWriting BAG_verblijfsobject_Drenthe: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Drenthe.geojson  size=218980527 bytes\n  -> Writing province: Zuid-Holland\nWriting BAG_Zuid-Holland: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Zuid-Holland_01.geojson  size=1073737039 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Zuid-Holland_02.geojson  size=581700691 bytes\nWriting BAG_verblijfsobject_Zuid-Holland: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Zuid-Holland_01.geojson  size=1073757634 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Zuid-Holland_02.geojson  size=595933940 bytes\n  -> Writing province: Limburg\nWriting BAG_Limburg: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Limburg.geojson  size=780562802 bytes\nWriting BAG_verblijfsobject_Limburg: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Limburg.geojson  size=514854372 bytes\n  -> Writing province: Overijssel\nWriting BAG_Overijssel: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Overijssel.geojson  size=770987168 bytes\nWriting BAG_verblijfsobject_Overijssel: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Overijssel.geojson  size=502234752 bytes\n  -> Writing province: Zeeland\nWriting BAG_Zeeland: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Zeeland.geojson  size=312945232 bytes\nWriting BAG_verblijfsobject_Zeeland: 1 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Zeeland.geojson  size=204658840 bytes\n  -> Writing province: Noord-Brabant\nWriting BAG_Noord-Brabant: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Noord-Brabant_01.geojson  size=1073737284 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_Noord-Brabant_02.geojson  size=713675417 bytes\nWriting BAG_verblijfsobject_Noord-Brabant: 2 chunk(s)\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Noord-Brabant_01.geojson  size=1073748179 bytes\n  -> file:/lakehouse/default/Files/BAG_geojson_province_WGS84_4326_202602_v02/BAG_verblijfsobject_Noord-Brabant_02.geojson  size=72555811 bytes\n\nAll files processed.\n"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"76f82622-a2af-44e9-923d-c4bb6c68f12f\",\"activityId\":\"83c40b2b-b419-4d14-baf9-37efeb6f1d82\",\"applicationId\":\"application_1770111049520_0001\",\"jobGroupId\":\"9\",\"advices\":{\"warn\":29,\"error\":1}}"}},"id":"7864c2be-5c79-4017-af8e-53695c8e72ca"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"8e7fad1d-4786-4df3-8f1f-ac696fe37fb2"},{"id":"eced916b-cb8e-421a-ae97-5287212e91f6"}],"default_lakehouse":"eced916b-cb8e-421a-ae97-5287212e91f6","default_lakehouse_name":"lh_geo_test_01","default_lakehouse_workspace_id":"92f195ae-6a05-4efe-97a5-94dd91debd3d"},"environment":{"environmentId":"167774a0-040d-4a49-9497-bdc5f0b1604f","workspaceId":"92f195ae-6a05-4efe-97a5-94dd91debd3d"}}},"nbformat":4,"nbformat_minor":5}